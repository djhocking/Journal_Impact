In recent years, the increased emphasis placed on citation metrics has been accompanied by a profusion of different varieties of these metrics. So much so that it can be hard to know which ones to use. In this paper, the author compares 11 different metrics of journal influence, exploring their weaknesses and their advantages, and looking at correlations of each with each other. The paper is nicely done, and it is impressive to see this work all laid out as it is in Figure 1. I would like to see it acknowledge a previous effort in this direction: Johan Bollen, Herbert Van de Sompel, Aric Hagberg and Ryan Chute. A Principal Component Analysis of 39 Scientific Impact Measures. PLoS ONE, June 2009. 

The author deftly avoids the pitfalls that undercut Davis's (2008) interpretation of correlation coefficients, but he might find relevant our discussion of these issues: J.D. West, T.C. Bergstrom, C.T. Bergstrom (2010) Big Macs and Eigenfactor Scores: Don't Let Correlation Coefficients Fool You, Journal of the American Society for Information Science & Technology. 61(9): 1800-1807

I have only quite minor concerns about the paper. On page 11, the author writes "Among the top 20 journals, the biggest difference in rank by metric was Molecular Ecology, which was ranked 9th by the JIF5 but dropped to 21st by the AI score and 20th by the SNIP. This suggests that while the average Molecular Ecology article was highly cited, the influence of those articles did not spread as much through science as a whole. "

This is not how I would interpret the fact that Molecular Ecology is rated much higher by JIF5 than by AI. What is going on here is that molecular ecology receives a larger fraction of its citations from molecular journals. Citations from such journals turn out to be worth less in the network algorithm than are citations from ecology journals, because of differing citation practices in the different fields. (See B. M. Althouse, J. D. West, T. C. Bergstrom, and C. T. Bergstrom (2009) Differences in impact factor across fields and over time Journal of the American Society for Information Science and Technology, 60: 27-34). 

I have a similar concern about the discussion of The American Naturalist on the next page. The author writes "The AI and SJR, which account for the scientific citation network, both rank the American Naturalist higher than the JIF5 or SNIP, which only account for the number of citations to a given journal directly. This suggests a better spread of ideas through science than indicated by single-level citation metrics. "

Again, this is not because of the spread through science so much as the fact that American Naturalist is drawing its citations from ecology journals; such citations turn out to be quite valuable in the Eigenfactor scoring system.

Carl Bergstrom